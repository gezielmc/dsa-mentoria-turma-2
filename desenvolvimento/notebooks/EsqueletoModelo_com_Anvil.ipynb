{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EsqueletoModelo com Anvil.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tq2dIVVZjePU"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mzkQpy5KHm-"
      },
      "source": [
        "# Esqueleto para o Algorimo de Recomendação\n",
        "\n",
        "Ações:\n",
        "treinar, salvar modelo, carregar modelo e predição\n",
        "\n",
        "```\n",
        "# Isto está formatado como código\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7HsPCT_KHKY"
      },
      "source": [
        "import uuid\n",
        "\n",
        "def train_model(csv_filename):\n",
        "  print('read csv and train the model, grid search is optional')\n",
        "  model = 'final model'\n",
        "  return model\n",
        "\n",
        "def save_model(model):\n",
        "  # nome auto gerado\n",
        "  # model_filename = 'c3256d66-e1cb-45fa-8ccd-c39355466c03.model'\n",
        "  model_filename = str(uuid.uuid4()) + '.model'\n",
        "  print('something like model.save(model_filename)')\n",
        "  return model_filename\n",
        "\n",
        "def load_model(model_filename):\n",
        "  print('something like model = something.load(model_filename)')\n",
        "  model = 'loaded model'\n",
        "  return model\n",
        "\n",
        "def predict(model, product_id):\n",
        "  print('something model.predict([product_id])')\n",
        "  result = [12, 48, 98, 88, 99]\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyIFtGg7LtnF"
      },
      "source": [
        "# Teste e uso no Anvil"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXSjUlzoLqR3",
        "outputId": "2e24bc1a-8bb3-4022-a93e-acd7d70dc855"
      },
      "source": [
        "# part 1 - training\n",
        "csv_filename = 'casasbahia.csv'\n",
        "print('training model...')\n",
        "model = train_model(csv_filename)\n",
        "print('saving model...')\n",
        "model_filename = save_model(model)\n",
        "print(f'model saved to {model_filename}')\n",
        "\n",
        "# part 2 - predicting\n",
        "print('loading saved model from disk...')\n",
        "model = load_model(model_filename)\n",
        "product_id = 25\n",
        "print(f'predicting product {product_id}..')\n",
        "result = predict(model, product_id)\n",
        "print(f'prediction result={result}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training model...\n",
            "read csv and train the model, grid search is optional\n",
            "saving model...\n",
            "something like model.save(model_filename)\n",
            "model saved to dda1620d-9ead-4e1d-8319-bdea7b0e7cea.model\n",
            "loading saved model from disk...\n",
            "something like model = something.load(model_filename)\n",
            "predicting product 25..\n",
            "something model.predict([product_id])\n",
            "prediction result=[12, 48, 98, 88, 99]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71ClTyvJ8e8x"
      },
      "source": [
        "## Conexão com o Anvil\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvA9yZaN8clo"
      },
      "source": [
        "#!pip install anvil-uplink\n",
        "import anvil.server\n",
        "anvil.server.connect(\"BFSI2NTMXOF7JIPPVF5FMCBY-55DIUIXG7VVL3GVJ\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3F3GhExt9EHd",
        "outputId": "f7290dd3-c42e-4b7d-b279-9519fc9b226a"
      },
      "source": [
        "############### thread python para o serviço do Anvil rodar em background ########## opcional\n",
        "\n",
        "from threading import Thread\n",
        "import time\n",
        "\n",
        "\n",
        "def thread_anvil():\n",
        "  print('Inicio da thread...')    \n",
        "  anvil.server.wait_forever() \n",
        "  print('Thread do serviço Anvil acionada...')\n",
        "\n",
        "print('Iniciando a thread do serviço Anvil...')\n",
        "\n",
        "# criar e executa a thread\n",
        "#t = Thread(target=thread_anvil, args=())\n",
        "#t.start()\n",
        "    \n",
        "print('Thread do serviço Anvil acionada...')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando a thread do serviço Anvil...\n",
            "Thread do serviço Anvil acionada...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUBun5qG9g-S"
      },
      "source": [
        "## Recebe o Arquivo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABEdS_Z29gC0"
      },
      "source": [
        "import anvil.media\n",
        "\n",
        "@anvil.server.callable\n",
        "def receive_file(file):\n",
        "  with anvil.media.TempFile(file) as filename:\n",
        "    img = load_image(filename)\n",
        "\n",
        "    ...."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlAKQUDPjOjD"
      },
      "source": [
        "# VERSÃO FINAL COM SURPRISE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6GWJ8cDn5kc",
        "outputId": "fc123d64-7403-4ce0-c0cf-376d588875cc"
      },
      "source": [
        "!pip install surprise"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.1.tar.gz (11.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8 MB 17.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.15.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp37-cp37m-linux_x86_64.whl size=1619419 sha256=d5261a1e9c2807cde6bd225cb6d5469973967f8faa797b5fbb573da79ac02f3c\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/44/74/b498c42be47b2406bd27994e16c5188e337c657025ab400c1c\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.1 surprise-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfovpeZBjavi"
      },
      "source": [
        "import uuid\n",
        "import sys\n",
        "import os\n",
        "import pickle\n",
        "import time\n",
        "from collections import defaultdict\n",
        "from surprise.prediction_algorithms import knns\n",
        "from surprise import SVD\n",
        "from surprise import Dataset\n",
        "from threading import Thread\n",
        "\n",
        "\n",
        "def get_top_n(predictions, n=10):\n",
        "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
        "\n",
        "    Args:\n",
        "        predictions(list of Prediction objects): The list of predictions, as\n",
        "            returned by the test method of an algorithm.\n",
        "        n(int): The number of recommendation to output for each user. Default\n",
        "            is 10.\n",
        "\n",
        "    Returns:\n",
        "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
        "        [(raw item id, rating estimation), ...] of size n.\n",
        "    \"\"\"\n",
        "\n",
        "    # First map the predictions to each user.\n",
        "    top_n = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_n[uid].append((iid, est))\n",
        "\n",
        "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        if n:\n",
        "          top_n[uid] = user_ratings[:n]\n",
        "        else:\n",
        "          top_n[uid] = user_ratings\n",
        "\n",
        "    return top_n\n",
        "\n",
        "\n",
        "def train_model(csv_filename, n=None):\n",
        "  start = time.time()\n",
        "  # TODO: alterar para ler .csv\n",
        "  # print('loading from dataset')\n",
        "  # df = pd.read_csv(csv_filename)\n",
        "  # data = Dataset.load_from_df(df[['UserId', 'ProductId', 'Rating']], Reader(rating_scale=(1,5)))\n",
        "  data = Dataset.load_builtin('ml-100k')\n",
        "  trainset = data.build_full_trainset()\n",
        "  algo = SVD(random_state=1)\n",
        "  algo.fit(trainset)\n",
        "\n",
        "  # Than predict ratings for all pairs (u, i) that are NOT in the training set.\n",
        "  testset = trainset.build_anti_testset()\n",
        "  predictions = algo.test(testset)\n",
        "\n",
        "  model = get_top_n(predictions, n=n)\n",
        "  elapsed_seconds = time.time() - start\n",
        "  print(f'model trained in {elapsed_seconds:.1f} seconds')\n",
        "  save_model(model)\n",
        "  return model\n",
        "\n",
        "@anvil.server.callable\n",
        "def thread_train_model(csv_filename, n=None):\n",
        "# criar e executa a thread\n",
        "  t = Thread(target=train_model, args=(csv_filename, n))\n",
        "  t.start()  \n",
        "  print('Thread do serviço de treinamento acionada...')\n",
        "  return t.getName\n",
        "\n",
        "def save_model(model):\n",
        "  tamanho_modelo = sys.getsizeof(model)\n",
        "  print(f'tamanho do modelo: {tamanho_modelo} bytes')\n",
        "  file_name = str(uuid.uuid4()) + '.model'\n",
        "  pickle.dump(model, open(file_name, 'wb'))\n",
        "  tamanho_arquivo = os.stat(file_name).st_size\n",
        "  print(f'tamanho do arquivo: {tamanho_arquivo} bytes')\n",
        "  return file_name\n",
        "\n",
        "def load_model(file_name):\n",
        "  print('Carregando o modelo')\n",
        "  file_name = file_name + '.model'\n",
        "  loaded_model = pickle.load(open(file_name, 'rb'))\n",
        "  print (\"Modelo carregado\")\n",
        "  return loaded_model\n",
        "\n",
        "\n",
        "@anvil.server.callable\n",
        "def predict_user(model_filename, user_id, n=5):\n",
        "  print(model_filename)\n",
        "  model = load_model(model_filename)\n",
        "  print('tamanho modelo: ', len(model))\n",
        "  print(f'predicting user {user_id}..')\n",
        "  result = []\n",
        "  # Print the recommended items for each user\n",
        "  for uid, user_ratings in model.items():\n",
        "    print('uid: ', uid)\n",
        "    if str(uid) == str(user_id):\n",
        "      result = [iid for (iid, _) in user_ratings][:n]\n",
        "  print ('Predict_user2:', result)\n",
        "  return result  \n",
        "\n",
        "@anvil.server.callable\n",
        "def predict_item(model_filename, item_id, n=5):\n",
        "  print('Predicting for item: ', item_id)\n",
        "  model = load_model(model_filename)\n",
        "  result = []\n",
        "  # Print the recommended items for each user\n",
        "  print('step 1')\n",
        "  top_n_iid = defaultdict(list)\n",
        "  for uid, user_ratings in model.items():\n",
        "    for (iid, rating) in user_ratings:\n",
        "      if str(iid) == str(item_id):\n",
        "        top_n_iid[iid].append((uid, rating))   \n",
        "  print('top_n_iid:')\n",
        "  print(top_n_iid)           \n",
        "  print('step 2')\n",
        "  # Then sort the predictions for each user and retrieve the k highest ones.\n",
        "  for iid, user_ratings in top_n_iid.items():\n",
        "    user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "  print('step 3')\n",
        "  result = [iid for (iid, _) in user_ratings][:n]\n",
        "  print('result: ')\n",
        "  print(result)\n",
        "  return result  \n",
        "\n",
        "\n",
        "@anvil.server.callable\n",
        "def predict_user_item(model_filename, user_id, item_id):\n",
        "  model = load_model(model_filename)\n",
        "  result = []\n",
        "  # Print the recommended items for each user\n",
        "  for uid, user_ratings in model.items():\n",
        "    if str(uid) == str(user_id):\n",
        "      for (iid, rating) in user_ratings:\n",
        "        if str(iid) == str(item_id):\n",
        "          result.append(rating)\n",
        "  return result  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkFpNYvHbnk1"
      },
      "source": [
        "# part 2 - predicting\n",
        "# print(model_filename)\n",
        "model = load_model(model_filename)\n",
        "user_id = 196\n",
        "print(f'predicting user {user_id}..')\n",
        "result_user = predict_user(model_filename, user_id, n=5)\n",
        "print(f'prediction result={result_user}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDFuqYbX9M2H",
        "outputId": "add727fe-adbb-4c46-9849-05f49f93c71e"
      },
      "source": [
        "################### aqui roda o serviço e faz todos os prints das APIs acionadas ####### essa é a melhor opção para rodas\n",
        "anvil.server.wait_forever()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting for item:  98\n",
            "Carregando o modelo\n",
            "Modelo carregado\n",
            "step 1\n",
            "top_n_iid:\n",
            "defaultdict(<class 'list'>, {'98': [('196', 4.6788753121780635), ('22', 4.695825459687281), ('244', 4.55397707888762), ('166', 4.387311362228051), ('286', 4.8236920474947), ('224', 4.06359872134985), ('122', 4.587093950293811), ('119', 4.559849491116247), ('167', 4.1380079404187615), ('38', 4.37488916014183), ('63', 3.9032836204227555), ('160', 4.823509371300489), ('50', 4.7136145526077735), ('157', 5), ('181', 2.7278056871620526), ('284', 4.494913849097564), ('242', 4.684088400431999), ('251', 4.784624344229448), ('260', 4.892963732541499), ('87', 4.6010178305445555), ('57', 4.754425691531723), ('223', 4.385917347833458), ('189', 4.337727874297825), ('243', 4.209806829163393), ('241', 4.322181791438202), ('127', 4.895241084218646), ('8', 4.376824220592425), ('162', 4.173571757201392), ('279', 3.359962383678984), ('32', 4.181634776473936), ('265', 4.585850589985849), ('168', 4.596132736455048), ('110', 4.32095676310213), ('82', 3.9594690087770257), ('155', 3.9157172911887477), ('68', 3.9655328994947183), ('172', 3.4870395942019354), ('19', 4.189195431881317), ('80', 3.970926464055128), ('66', 4.12245160766342), ('26', 4.121211857027876), ('15', 4.307282460645637), ('52', 4.819624733647866), ('83', 4.062763827190706), ('54', 4.516145769907754), ('294', 4.63087361007677), ('229', 3.557342227548917), ('36', 4.6619463704618544), ('70', 4.165661132881116), ('192', 4.491773858733929), ('100', 3.9205085484449484), ('307', 4.60744939599568), ('193', 4.088927046229866), ('113', 4.309459926620852), ('219', 4.391446321760305), ('158', 4.3633324860177485), ('302', 3.9538419888457526), ('33', 4.906348006807797), ('154', 4.016292637552307), ('187', 4.489225532759625), ('170', 4.828055357092604), ('101', 3.802552804826945), ('112', 4.502082018814523), ('133', 3.6586632927785554), ('104', 3.6558399818204044), ('240', 4.787223325459797), ('191', 4.596601123184828), ('61', 4.260351958248478), ('142', 4.286968591326129), ('203', 4.209616569872398), ('197', 4.210369796981437), ('134', 4.009271510306941), ('137', 4.750720872938441), ('257', 4.675747190222524), ('111', 4.352650349241745), ('285', 4.451025612482042), ('116', 3.8085153959371256), ('73', 4.370299184369627), ('221', 4.3866634290316044), ('235', 4.367887352963021), ('164', 4.420881517271848), ('281', 4.239189213454092), ('182', 4.599859564178067), ('129', 3.578951686199997), ('45', 4.460745907384618), ('131', 4.3478962377041555), ('126', 3.9029348057768476), ('231', 3.9215797610343337), ('217', 4.2076872960613), ('79', 4.294093045641904), ('75', 4.572749426711887), ('245', 4.1406959418867855), ('282', 4.585278676427728), ('78', 4.736280152961062), ('283', 4.838971604238689), ('171', 3.9366488840082297), ('107', 3.7053602193445063), ('306', 4.50326214535204), ('173', 5), ('185', 4.1520410656913445), ('150', 4.514275452422667), ('165', 4.543043313670221), ('208', 4.310682349486299), ('2', 3.995982266925212), ('205', 3.816305754505659), ('93', 4.3337028997750995), ('159', 4.613229623042624), ('146', 4.366649137124135), ('156', 3.924776478318715), ('37', 4.596712567068444), ('141', 4.253797388451647), ('195', 4.291155956969166), ('108', 4.641225532631387), ('47', 4.378700801917374), ('89', 4.54889649869703), ('140', 4.092993298372099), ('190', 4.543091330593249), ('17', 4.102042857329868), ('53', 4.5331252102007715), ('149', 3.9965479967214153), ('176', 4.68669521847872), ('106', 4.397065479737491), ('153', 4.025086009034602), ('220', 4.829013766035616), ('143', 4.460630201958977), ('199', 3.5076927345461177), ('202', 3.1488879453908165), ('277', 4.44776726607313), ('206', 3.3642731733449343), ('314', 4.398492899572959), ('136', 4.789346960631335), ('179', 4.175288190338721), ('4', 5), ('304', 4.445845077140239), ('3', 3.699351524894573), ('227', 4.360745081542655), ('252', 5), ('212', 4.282089212202078), ('310', 4.676420377361944), ('35', 4.264940272108442), ('147', 4.772904461822742), ('105', 4.469917792074698), ('34', 4.727995723072058), ('51', 4.115694255392891), ('204', 4.281387201306063), ('31', 4.316336611447627), ('318', 4.599857156797991), ('30', 4.703340621989429), ('120', 4.409935122549881), ('46', 4.598912665842859), ('289', 4.133855189360604), ('209', 3.9618532356366796), ('261', 5), ('88', 4.446308287604582), ('9', 4.892223096905049), ('247', 4.631992341409562), ('321', 4.014644263193554), ('266', 4.3061641715840135), ('74', 4.071340862724886), ('238', 4.125976944199486), ('319', 4.267210803817225), ('67', 4.828581773283083), ('211', 3.5792087347855803), ('98', 4.021458526021012), ('40', 3.8083264268374974), ('258', 4.429458551080181), ('320', 4.303040743966235), ('183', 3.998787565512817), ('322', 4.742204674628116), ('27', 4.05116122765775), ('331', 4.02367749431653), ('86', 4.36970014988043), ('139', 4.440617599669354), ('300', 4.721998731655304), ('39', 4.419723694535701), ('324', 5), ('132', 4.028910052185984), ('336', 4.158901294187205), ('335', 4.250082780594652), ('169', 4.423713563633098), ('338', 4.686202199169865), ('309', 4.552337190756351), ('340', 4.811083389697242), ('317', 4.5821743610046966), ('341', 4.782755485984209), ('273', 4.355586244821197), ('55', 4.345057602114277), ('349', 4.359435405243755), ('348', 4.964372186126306), ('351', 5), ('358', 4.089127771907366), ('360', 4.43516512667167), ('355', 5), ('362', 4.140646832468577), ('357', 5), ('356', 4.332314310484955), ('365', 4.234930121878207), ('373', 4.175470790799033), ('337', 4.65339206821776), ('375', 4.620131035891961), ('359', 4.615135672555377), ('381', 4.47734836235689), ('364', 4.489349914224926), ('369', 4.852878416823883), ('386', 4.486358589880601), ('383', 4.60135627717434), ('390', 4.364732246945363), ('393', 3.782747752706368), ('398', 4.319409960469678), ('397', 4.383452729864782), ('396', 4.043013384845444), ('401', 3.6745663893366736), ('402', 4.221138129593044), ('384', 4.735777950626398), ('353', 4.168363277564365), ('403', 4.496480712268782), ('400', 4.678200363761251), ('404', 4.260701183238229), ('413', 4.156623325613286), ('408', 4.72630551962485), ('410', 4.07703157440312), ('411', 4.108203463685082), ('412', 4.0972592445949845), ('420', 4.367519685943495), ('419', 4.538558410182178), ('415', 4.648930901421409), ('423', 4.433171073141174), ('428', 5), ('427', 5), ('418', 3.6402481902133266), ('424', 3.926640502788238), ('432', 4.609034747608302), ('433', 4.501306983255567), ('434', 4.671782767352773), ('438', 4.756793836066902), ('431', 4.417201426684818), ('440', 4.900718357332369), ('445', 2.666584446618495), ('449', 4.263481231864332), ('446', 3.8971171258100905), ('439', 4.6608335795103635), ('451', 3.676069626273158), ('414', 5), ('444', 4.577330919224862), ('448', 4.445295565110901), ('462', 5), ('460', 4.067667973859252), ('461', 3.8613658870104657), ('467', 4.279742932384665), ('472', 4.734365700700823), ('463', 3.8472034631405125), ('471', 4.176359799055254), ('469', 4.562076339559485), ('464', 4.768700222715858), ('476', 4.24706125839865), ('473', 4.39113686909906), ('470', 4.487653488364782), ('441', 4.487065398548314), ('479', 4.13891526184754), ('486', 4.476968823780527), ('482', 4.337966624233075), ('492', 3.7598232265038094), ('490', 3.7006942620047565), ('489', 4.526879697738981), ('483', 3.4642013690346354), ('477', 5), ('491', 3.9893026510879737), ('502', 4.326850817463112), ('506', 4.520434277379634), ('443', 4.332470855369782), ('507', 5), ('511', 4.698230347199291), ('515', 3.721124920602055), ('512', 4.765080613274801), ('513', 4.82133862323087), ('475', 4.3288191014105255), ('523', 4.959852232902918), ('518', 4.4408884034942115), ('509', 3.5690833071741817), ('516', 4.425033519590649), ('510', 4.112861593251857), ('501', 4.640218300900339), ('525', 4.496304781379193), ('521', 3.4147845258712275), ('520', 4.191840436093497), ('519', 4.920499392133554), ('528', 4.418017281019551), ('531', 4.1382454949269185), ('529', 4.4951512552821615), ('517', 3.912998316067721), ('527', 3.779927911974912), ('485', 3.945765081467681), ('526', 4.224650480886898), ('534', 5), ('541', 4.416336746029821), ('542', 4.098821592438442), ('539', 4.375158442567875), ('547', 4.56739915789369), ('522', 4.441829279967941), ('544', 3.930440446240176), ('552', 4.341086439218951), ('540', 4.561335668589119), ('550', 4.767271620688231), ('556', 4.848107438839735), ('559', 4.045353280327594), ('560', 4.164286784067287), ('563', 4.5940843416855826), ('557', 4.2840742725221), ('558', 4.630110757561327), ('564', 4.08816893348124), ('565', 4.707010028534095), ('573', 4.159554576266018), ('549', 4.620363877338105), ('567', 3.8102959944628667), ('569', 4.467858711068849), ('576', 4.321322186182409), ('574', 4.09231492941227), ('555', 4.469592177532549), ('572', 4.167232379592917), ('584', 4.272951618573544), ('587', 4.075561900904596), ('568', 3.618376866044323), ('586', 4.090990665234404), ('585', 4.204783833122088), ('582', 4.445717614987751), ('591', 4.371316745739968), ('581', 4.4083728169179945), ('580', 4.7497208412710075), ('590', 3.8581902789138374), ('583', 4.820368232513785), ('596', 4.613184796842451), ('570', 3.7347606834567766), ('599', 4.8840626159445915), ('589', 4.53668738581284), ('594', 3.824101712093535), ('597', 4.445133743517835), ('578', 3.759919516527596), ('602', 4.877716041827739), ('600', 4.605559365391415), ('603', 4.298264607893356), ('595', 4.4326923996201035), ('607', 4.272900507194908), ('611', 4.496359844290897), ('614', 4.033871574265504), ('609', 3.424405056807808), ('615', 4.234411011172707), ('616', 4.798230234572866), ('571', 3.7309817840478967), ('619', 4.036117062627863), ('613', 4.81540989123403), ('621', 4.852916547777768), ('624', 4.698407580086447), ('612', 4.051655795520625), ('627', 3.749236277375564), ('623', 3.9850874510955734), ('628', 5), ('625', 3.767263839210228), ('631', 4.409571339426835), ('634', 4.231766117824065), ('642', 2.8012084312370993), ('637', 3.2652152119610007), ('640', 4.709793721726735), ('626', 3.5651641775759524), ('598', 4.444368938391355), ('635', 4.12214894629575), ('644', 4.71254553913724), ('636', 4.809121084885673), ('647', 4.480233467331406), ('651', 4.447692347491801), ('649', 4.581949731385266), ('656', 3.7674692135921677), ('646', 3.9745237792617045), ('657', 3.7706590647334783), ('661', 4.505236781833573), ('662', 4.248935011239374), ('641', 4.3004494531752115), ('668', 3.9461057439488165), ('673', 4.5619630203027715), ('669', 4.172078798339762), ('676', 4.024286895904544), ('674', 4.319093118082941), ('652', 3.8973308755853373), ('677', 4.38831742826014), ('679', 4.2939668837517395), ('685', 3.3057321835988853), ('683', 4.1362235108452206), ('672', 4.24906868922453), ('692', 4.369082380999915), ('689', 4.349495100534715), ('688', 5), ('697', 4.3983217151433), ('698', 2.640986570643734), ('705', 3.971774078467524), ('701', 5), ('707', 3.9156546643393586), ('687', 4.6610311438879295), ('695', 4.114238617427065), ('675', 4.27931002504026), ('708', 4.312175089957122), ('710', 4.179035638129989), ('712', 4.175090106350607), ('713', 3.806970876923947), ('681', 3.9193650805611457), ('678', 4.170497548749731), ('702', 3.810364579133405), ('721', 3.9655301730351407), ('714', 4.262264231807186), ('717', 4.4252427893820485), ('718', 4.636456434577836), ('696', 4.338371718419963), ('722', 4.398107579893008), ('724', 3.4728819704513776), ('725', 4.449265039489608), ('706', 4.277423384517975), ('720', 4.425899201460458), ('729', 3.6583207021772046), ('726', 4.325775300634204), ('728', 4.443496968257715), ('703', 4.512816267140874), ('736', 4.184793997252855), ('730', 3.657691519334699), ('743', 4.381785713723078), ('742', 4.276033902518511), ('737', 4.386737696581491), ('733', 4.025210257187538), ('740', 4.326777644705492), ('735', 4.15868841039338), ('723', 3.819362329283503), ('748', 3.886579776349178), ('746', 4.36432401464999), ('731', 4.327143447251883), ('750', 4.314557927095855), ('756', 3.540529588166036), ('752', 4.002849211025024), ('732', 4.731543962806909), ('762', 3.698167000184442), ('744', 4.011983572040174), ('754', 4.056577341145644), ('769', 4.101388333447421), ('755', 3.985309039320332), ('768', 4.121553339150287), ('765', 4.2344852967396776), ('772', 4.884367907098875), ('761', 3.9985916893252207), ('777', 4.360105550254385), ('759', 4.533998697287786), ('779', 4.68009220736987), ('782', 3.622182234733418), ('784', 5), ('770', 5), ('789', 4.191396869306494), ('787', 3.597635949346279), ('783', 4.616840006107585), ('785', 4.164246570963287), ('794', 4.714399787234169), ('781', 4.175716117473199), ('795', 3.461880745674438), ('793', 4.564301001650614), ('791', 4.509339481268799), ('800', 4.460871487941547), ('803', 4.195101654528072), ('775', 4.678939817197382), ('792', 3.6984211831699385), ('799', 4.619836994952642), ('807', 4.6719005251599235), ('797', 3.7646131849146465), ('801', 4.94686710610024), ('809', 4.243967408655082), ('817', 4.531791869514534), ('818', 4.0835670835595455), ('812', 4.001587865425018), ('827', 4.230524147093665), ('829', 4.093129770154054), ('811', 5), ('826', 4.654864904191105), ('831', 4.3978872835048985), ('819', 4.863124311308121), ('828', 3.9808558914098797), ('808', 5), ('836', 4.65572367694263), ('816', 4.837781274981019), ('838', 4.797292160714755), ('839', 3.679052347107602), ('832', 4.027794159791535), ('810', 5), ('844', 4.096082834908131), ('834', 4.603712910795041), ('837', 4.011610618347198), ('813', 3.878220325046939), ('842', 4.565123199289437), ('848', 4.653153581079743), ('822', 4.133434901331171), ('852', 4.353860287203264), ('851', 4.599202978408905), ('849', 5), ('858', 4.350282534331736), ('853', 4.448103763958644), ('855', 3.5664073259800313), ('824', 4.075044238304884), ('845', 3.9562228215801283), ('841', 4.462679337073542), ('859', 4.324824249596144), ('856', 4.4289820849843755), ('820', 4.252643368637456), ('863', 4.311091280940564), ('860', 3.95199311412488), ('857', 4.040436667704699), ('865', 3.2832209538568247), ('861', 4.641441417116882), ('871', 4.1263999570731285), ('876', 4.738209505059545), ('872', 4.219527209862377), ('866', 3.283877587784524), ('873', 4.0448594175494845), ('869', 4.156334563184788), ('879', 4.624548543900165), ('884', 4.644478983997776), ('885', 3.6020329605298285), ('874', 4.438632794339349), ('893', 4.529498095915133), ('891', 4.732027762240855), ('894', 4.3886182272158285), ('901', 4.326294851830356), ('904', 4.254161217751241), ('905', 3.998401718317301), ('902', 4.213491229603168), ('898', 4.7555338567030825), ('895', 4.677364594263395), ('906', 4.516700952827599), ('900', 3.0745815077182232), ('912', 4.492887846248053), ('914', 3.9064439771522763), ('918', 3.36440262756766), ('921', 3.6780027277003366), ('915', 3.575280375570386), ('923', 5), ('927', 4.099149186410127), ('924', 4.080425467382085), ('931', 4.371057597619533), ('917', 4.54651950290593), ('909', 4.9240736754598515), ('934', 4.189769858436121), ('935', 4.592181668818386), ('938', 4.487662025395849), ('888', 4.6910510244973365), ('942', 4.8362694583643515), ('937', 3.9034597392594397), ('926', 4.218958701447514), ('939', 5), ('936', 4.481307955311864), ('930', 3.45437598605842), ('920', 4.089283734575059), ('941', 4.7483273078178785)]})\n",
            "step 2\n",
            "step 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWfsPNm_U1-H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq2dIVVZjePU"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UmPIDVaje-9",
        "outputId": "73dd34dd-13df-4d8b-8b6d-9c4dba99c947"
      },
      "source": [
        "# part 1 - training\n",
        "csv_filename = 'ratings_Beauty.csv'\n",
        "print('training model...')\n",
        "model = train_model(csv_filename)\n",
        "print('saving model...')\n",
        "model_filename = save_model(model)\n",
        "print(f'model saved to {model_filename}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training model...\n",
            "Dataset ml-100k could not be found. Do you want to download it? [Y/n] \n",
            "Trying to download dataset from http://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
            "Done! Dataset ml-100k has been saved to /root/.surprise_data/ml-100k\n",
            "model trained in 26.2 seconds\n",
            "saving model...\n",
            "tamanho do modelo: 36984 bytes\n",
            "tamanho do arquivo: 62238699 bytes\n",
            "model saved to 21649d8e-b8da-4d06-8fcb-43a4ce369fe9.model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wp_OBKOBjkpv"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69wwvHuNjnHr",
        "outputId": "7ffbb0d1-26f6-429b-ec53-f4c011364fcf"
      },
      "source": [
        "# part 2 - predicting\n",
        "print('loading saved model from disk...')\n",
        "print(model_filename)\n",
        "model = load_model(model_filename)\n",
        "#print('modelo: ', model)\n",
        "user_id = 196\n",
        "print(f'predicting user {user_id}..')\n",
        "result_user = predict_user(model_filename, user_id, n=5)\n",
        "print(f'prediction result={result_user}')\n",
        "\n",
        "if len(result_user) > 0:\n",
        "  item_id = result_user[0]\n",
        "  print(f'predicting item {item_id}..')\n",
        "  result_item = predict_item(model, item_id, n=5)\n",
        "  print(f'prediction result={result_item}')\n",
        "  if len(result_item) > 0:\n",
        "    print(f'predicting item {item_id} for user {user_id}..')\n",
        "    result_user_item = predict_user_item(model, user_id, item_id)\n",
        "    print(f'prediction result={result_user_item}')  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading saved model from disk...\n",
            "21649d8e-b8da-4d06-8fcb-43a4ce369fe9.model\n",
            "Carregando o modelo\n",
            "Modelo carregado\n",
            "predicting user 196..\n",
            "loading saved model from disk...\n",
            "21649d8e-b8da-4d06-8fcb-43a4ce369fe9.model\n",
            "Carregando o modelo\n",
            "Modelo carregado\n",
            "predicting user 196..\n",
            "tamanho modelo:  943\n",
            "Predict_user2: ['98', '64', '408', '318', '483']\n",
            "prediction result=['98', '64', '408', '318', '483']\n",
            "predicting item 98..\n",
            "prediction result=['157', '173', '4', '252', '261']\n",
            "predicting item 98 for user 196..\n",
            "prediction result=[4.6788753121780635]\n"
          ]
        }
      ]
    }
  ]
}